{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a4c313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:20:44.871389Z",
     "iopub.status.busy": "2023-12-27T09:20:44.871005Z",
     "iopub.status.idle": "2023-12-27T09:20:58.229239Z",
     "shell.execute_reply": "2023-12-27T09:20:58.227925Z"
    },
    "papermill": {
     "duration": 13.365437,
     "end_time": "2023-12-27T09:20:58.232209",
     "exception": false,
     "start_time": "2023-12-27T09:20:44.866772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Define label extractor for train samples\n",
    "def extract_train_label(file_path, class_names, devel_files, y_devel):\n",
    "    \n",
    "    # Split file path into parts\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # Extract class dir name\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Find index of maximum\n",
    "    label = tf.argmax(one_hot)\n",
    "    \n",
    "    return label\n",
    "\n",
    "# Define label extractor for devel samples\n",
    "def extract_devel_label(file_path, class_names, devel_files, y_devel):\n",
    "    \n",
    "    # One-hot encode indices\n",
    "    idx_hot = devel_files == file_path\n",
    "    # Find index\n",
    "    idx = tf.argmax(idx_hot)\n",
    "    # Extract class name\n",
    "    class_name = tf.gather(y_devel, idx)\n",
    "\n",
    "    # Extract class dir name\n",
    "    one_hot = class_name == class_names\n",
    "    # Find index of maximum\n",
    "    label = tf.argmax(one_hot)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81ba937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:20:58.238957Z",
     "iopub.status.busy": "2023-12-27T09:20:58.238275Z",
     "iopub.status.idle": "2023-12-27T09:20:58.248541Z",
     "shell.execute_reply": "2023-12-27T09:20:58.247639Z"
    },
    "papermill": {
     "duration": 0.015837,
     "end_time": "2023-12-27T09:20:58.250644",
     "exception": false,
     "start_time": "2023-12-27T09:20:58.234807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define sample preprocessing pipeline\n",
    "def process_path(file_path, class_names, devel_files, y_devel, label_fun=extract_train_label, cut=224, S=256, max_delta=0.2):\n",
    "    \n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "   \n",
    "    # Find rescaling factor\n",
    "    min_side = tf.math.minimum(tf.shape(image)[0], tf.shape(image)[1])\n",
    "    scale = S / min_side\n",
    "    \n",
    "    # Zero-mean the RGB values by ImageNet Mean\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "\n",
    "    # Compute new dimensions\n",
    "    new_height = tf.cast(tf.shape(image)[0], tf.float64) * scale\n",
    "    new_width = tf.cast(tf.shape(image)[1], tf.float64) * scale\n",
    "    \n",
    "    # Convert to float\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Rescale by S\n",
    "    image = tf.image.resize(image, size=(new_height, new_width), preserve_aspect_ratio=True)\n",
    "    # Crop randomly\n",
    "    image = tf.image.random_crop(image, size=[cut, cut, 3])\n",
    "    # adjust RGB values by random amount\n",
    "    image = tf.image.random_hue(image, max_delta=max_delta)\n",
    "    \n",
    "    label = label_fun(file_path, class_names, devel_files, y_devel)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dbef7f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:20:58.257085Z",
     "iopub.status.busy": "2023-12-27T09:20:58.256455Z",
     "iopub.status.idle": "2023-12-27T09:20:58.262380Z",
     "shell.execute_reply": "2023-12-27T09:20:58.261171Z"
    },
    "papermill": {
     "duration": 0.011877,
     "end_time": "2023-12-27T09:20:58.264894",
     "exception": false,
     "start_time": "2023-12-27T09:20:58.253017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Generate SGD optimiser\n",
    "def create_optimiser():\n",
    "    \n",
    "    sgd_optimiser = keras.optimizers.experimental.SGD(\n",
    "            learning_rate=1e-2,\n",
    "            momentum=0.9,\n",
    "            nesterov=False,\n",
    "            weight_decay=5e-4\n",
    "        )\n",
    "    \n",
    "    return sgd_optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f88f17a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:20:58.271356Z",
     "iopub.status.busy": "2023-12-27T09:20:58.270970Z",
     "iopub.status.idle": "2023-12-27T09:20:58.281386Z",
     "shell.execute_reply": "2023-12-27T09:20:58.280276Z"
    },
    "papermill": {
     "duration": 0.016259,
     "end_time": "2023-12-27T09:20:58.283743",
     "exception": false,
     "start_time": "2023-12-27T09:20:58.267484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Build VGG11 model\n",
    "def design_vgg11(class_num, input_shape, kernel_size, padding, activation, pool_size, strides):\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        # 1st convolutional block\n",
    "        layers.Conv2D(input_shape=input_shape, filters=64, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 2nd convolutional block\n",
    "        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 3rd convolutional block\n",
    "        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 4th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 5th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # Classifier head\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation=activation),\n",
    "        layers.Dropout(rate=0.5),\n",
    "        layers.Dense(4096, activation=activation),\n",
    "        layers.Dropout(rate=0.5),\n",
    "        layers.Dense(class_num)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155ee9a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:20:58.290667Z",
     "iopub.status.busy": "2023-12-27T09:20:58.290246Z",
     "iopub.status.idle": "2023-12-27T09:20:58.299950Z",
     "shell.execute_reply": "2023-12-27T09:20:58.299146Z"
    },
    "papermill": {
     "duration": 0.015709,
     "end_time": "2023-12-27T09:20:58.302015",
     "exception": false,
     "start_time": "2023-12-27T09:20:58.286306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build VGG13 model\n",
    "def design_vgg13(model_file, layer_positions=[0, 2, 4, 5, 14, 16, 18]):\n",
    "    \n",
    "    # Import pretrained base\n",
    "    pretrained_base = keras.models.load_model(model_file)\n",
    "    \n",
    "    # Select relevant layers\n",
    "    pretrained_layers = [pretrained_base.get_layer(index=i) for i in layer_positions]\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        # 1st convolutional block\n",
    "        pretrained_layers[0],\n",
    "        layers.Conv2D(filters=64, kernel_size=KERNEL_SIZE, padding=PAD_MODE, activation=ACTIVATION),\n",
    "        layers.MaxPooling2D(pool_size=POOL_SIZE, strides=POOL_STRIDES),\n",
    "\n",
    "        # 2nd convolutional block\n",
    "        pretrained_layers[1],\n",
    "        layers.Conv2D(filters=128, kernel_size=KERNEL_SIZE, padding=PAD_MODE, activation=ACTIVATION),\n",
    "        layers.MaxPooling2D(pool_size=POOL_SIZE, strides=POOL_STRIDES),\n",
    "\n",
    "        # 3rd convolutional block\n",
    "        pretrained_layers[2],\n",
    "        pretrained_layers[3],\n",
    "        layers.MaxPool2D(pool_size=POOL_SIZE, strides=POOL_STRIDES),\n",
    "\n",
    "        # 4th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=POOL_SIZE, strides=POOL_STRIDES),\n",
    "\n",
    "        # 5th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=POOL_SIZE, strides=POOL_STRIDES),\n",
    "\n",
    "        # Classifier head\n",
    "        layers.Flatten(),\n",
    "        pretrained_layers[4],\n",
    "        layers.Dropout(rate=0.5),\n",
    "        pretrained_layers[5],\n",
    "        layers.Dropout(rate=0.5),\n",
    "        pretrained_layers[6],\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.75217,
   "end_time": "2023-12-27T09:20:59.627037",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-27T09:20:41.874867",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
