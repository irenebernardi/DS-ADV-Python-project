{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194a97e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:24:10.117608Z",
     "iopub.status.busy": "2023-12-27T10:24:10.117149Z",
     "iopub.status.idle": "2023-12-27T10:24:25.251819Z",
     "shell.execute_reply": "2023-12-27T10:24:25.250592Z"
    },
    "papermill": {
     "duration": 15.145417,
     "end_time": "2023-12-27T10:24:25.256340",
     "exception": false,
     "start_time": "2023-12-27T10:24:10.110923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.random import set_seed\n",
    "from os import environ\n",
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "# Prepare a reproducible environment for model training and validation\n",
    "def reproduce_environment(random_state=123):\n",
    "\n",
    "    # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    environ[\"PYTHONHASHSEED\"] = str(random_state)\n",
    "\n",
    "    # 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "    seed(random_state)\n",
    "\n",
    "    # 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "    set_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9d7426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:24:25.266915Z",
     "iopub.status.busy": "2023-12-27T10:24:25.266068Z",
     "iopub.status.idle": "2023-12-27T10:24:25.276415Z",
     "shell.execute_reply": "2023-12-27T10:24:25.274436Z"
    },
    "papermill": {
     "duration": 0.018877,
     "end_time": "2023-12-27T10:24:25.279850",
     "exception": false,
     "start_time": "2023-12-27T10:24:25.260973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Define label extractor for train samples\n",
    "def extract_train_label(file_path, class_names, devel_files, y_devel):\n",
    "    \n",
    "    # Split file path into parts\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # Extract class dir name\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Find index of maximum\n",
    "    label = tf.argmax(one_hot)\n",
    "    \n",
    "    return label\n",
    "\n",
    "# Define label extractor for devel samples\n",
    "def extract_devel_label(file_path, class_names, devel_files, y_devel):\n",
    "    \n",
    "    # One-hot encode indices\n",
    "    idx_hot = devel_files == file_path\n",
    "    # Find index\n",
    "    idx = tf.argmax(idx_hot)\n",
    "    # Extract class name\n",
    "    class_name = tf.gather(y_devel, idx)\n",
    "\n",
    "    # Extract class dir name\n",
    "    one_hot = class_name == class_names\n",
    "    # Find index of maximum\n",
    "    label = tf.argmax(one_hot)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5fb8b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:24:25.289245Z",
     "iopub.status.busy": "2023-12-27T10:24:25.288703Z",
     "iopub.status.idle": "2023-12-27T10:24:25.301775Z",
     "shell.execute_reply": "2023-12-27T10:24:25.300148Z"
    },
    "papermill": {
     "duration": 0.021865,
     "end_time": "2023-12-27T10:24:25.305309",
     "exception": false,
     "start_time": "2023-12-27T10:24:25.283444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define sample preprocessing pipeline\n",
    "def process_path(file_path, class_names, devel_files, y_devel, label_fun=extract_train_label, cut=224, S=256, max_delta=0.2):\n",
    "    \n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "   \n",
    "    # Find rescaling factor\n",
    "    min_side = tf.math.minimum(tf.shape(image)[0], tf.shape(image)[1])\n",
    "    scale = S / min_side\n",
    "    \n",
    "    # Zero-mean the RGB values by ImageNet Mean\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "\n",
    "    # Compute new dimensions\n",
    "    new_height = tf.cast(tf.shape(image)[0], tf.float64) * scale\n",
    "    new_width = tf.cast(tf.shape(image)[1], tf.float64) * scale\n",
    "    \n",
    "    # Convert to float\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Rescale by S\n",
    "    image = tf.image.resize(image, size=(new_height, new_width), preserve_aspect_ratio=True)\n",
    "    # Crop randomly\n",
    "    image = tf.image.random_crop(image, size=[cut, cut, 3])\n",
    "    # adjust RGB values by random amount\n",
    "    image = tf.image.random_hue(image, max_delta=max_delta)\n",
    "    \n",
    "    label = label_fun(file_path, class_names, devel_files, y_devel)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380eebc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:24:25.313966Z",
     "iopub.status.busy": "2023-12-27T10:24:25.313445Z",
     "iopub.status.idle": "2023-12-27T10:24:25.321071Z",
     "shell.execute_reply": "2023-12-27T10:24:25.319602Z"
    },
    "papermill": {
     "duration": 0.014749,
     "end_time": "2023-12-27T10:24:25.323526",
     "exception": false,
     "start_time": "2023-12-27T10:24:25.308777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Generate SGD optimiser\n",
    "def create_optimiser():\n",
    "    \n",
    "    sgd_optimiser = keras.optimizers.experimental.SGD(\n",
    "            learning_rate=1e-2,\n",
    "            momentum=0.9,\n",
    "            nesterov=False,\n",
    "            weight_decay=5e-4\n",
    "        )\n",
    "    \n",
    "    return sgd_optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bb7310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:24:25.332515Z",
     "iopub.status.busy": "2023-12-27T10:24:25.331504Z",
     "iopub.status.idle": "2023-12-27T10:24:25.350088Z",
     "shell.execute_reply": "2023-12-27T10:24:25.348494Z"
    },
    "papermill": {
     "duration": 0.025944,
     "end_time": "2023-12-27T10:24:25.352605",
     "exception": false,
     "start_time": "2023-12-27T10:24:25.326661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Build VGG11 model\n",
    "def design_vgg11(class_num, input_shape, kernel_size, padding, activation, pool_size, strides):\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        # 1st convolutional block\n",
    "        layers.Conv2D(input_shape=input_shape, filters=64, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 2nd convolutional block\n",
    "        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 3rd convolutional block\n",
    "        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 4th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 5th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # Classifier head\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.Dropout(rate=0.5),\n",
    "        layers.Dense(4096, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.Dropout(rate=0.5),\n",
    "        layers.Dense(class_num, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1))\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91662404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:24:25.361963Z",
     "iopub.status.busy": "2023-12-27T10:24:25.360814Z",
     "iopub.status.idle": "2023-12-27T10:24:25.377150Z",
     "shell.execute_reply": "2023-12-27T10:24:25.375444Z"
    },
    "papermill": {
     "duration": 0.024375,
     "end_time": "2023-12-27T10:24:25.380321",
     "exception": false,
     "start_time": "2023-12-27T10:24:25.355946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Build VGG13 model\n",
    "def design_vgg13(model_file, kernel_size, padding, activation, pool_size, strides, layer_positions=[0, 2, 4, 5, 14, 16, 18]):\n",
    "    \n",
    "    # Import pretrained base\n",
    "    pretrained_base = keras.models.load_model(model_file)\n",
    "    \n",
    "    # Select relevant layers\n",
    "    pretrained_layers = [pretrained_base.get_layer(index=i) for i in layer_positions]\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        # 1st convolutional block\n",
    "        pretrained_layers[0],\n",
    "        layers.Conv2D(filters=64, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 2nd convolutional block\n",
    "        pretrained_layers[1],\n",
    "        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 3rd convolutional block\n",
    "        pretrained_layers[2],\n",
    "        pretrained_layers[3],\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 4th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 5th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation, kernel_initializer=keras.initializers.RandomNormal(stddev=0.1)),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # Classifier head\n",
    "        layers.Flatten(),\n",
    "        pretrained_layers[4],\n",
    "        layers.Dropout(rate=0.5),\n",
    "        pretrained_layers[5],\n",
    "        layers.Dropout(rate=0.5),\n",
    "        pretrained_layers[6],\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.467898,
   "end_time": "2023-12-27T10:24:28.037631",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-27T10:24:06.569733",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
