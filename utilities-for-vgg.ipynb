{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/giuliobenedetti/utilities-for-vgg?scriptVersionId=157103969\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"fdc3117f","metadata":{"execution":{"iopub.execute_input":"2023-12-30T13:33:54.815396Z","iopub.status.busy":"2023-12-30T13:33:54.814961Z","iopub.status.idle":"2023-12-30T13:34:10.095846Z","shell.execute_reply":"2023-12-30T13:34:10.094721Z"},"papermill":{"duration":15.289978,"end_time":"2023-12-30T13:34:10.098766","exception":false,"start_time":"2023-12-30T13:33:54.808788","status":"completed"},"tags":[]},"outputs":[],"source":["from tensorflow.random import set_seed\n","from os import environ\n","from random import seed\n","import numpy as np\n","\n","# Prepare a reproducible environment for model training and validation\n","def reproduce_environment(random_state=123):\n","\n","    # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n","    environ[\"PYTHONHASHSEED\"] = str(random_state)\n","\n","    # 2. Set the `python` built-in pseudo-random generator at a fixed value\n","    seed(random_state)\n","\n","    # 3. Set the `numpy` pseudo-random generator at a fixed value\n","    np.random.seed(random_state)\n","\n","    # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n","    set_seed(random_state)"]},{"cell_type":"code","execution_count":2,"id":"8ac0fae4","metadata":{"execution":{"iopub.execute_input":"2023-12-30T13:34:10.108148Z","iopub.status.busy":"2023-12-30T13:34:10.10746Z","iopub.status.idle":"2023-12-30T13:34:10.119668Z","shell.execute_reply":"2023-12-30T13:34:10.11826Z"},"papermill":{"duration":0.019808,"end_time":"2023-12-30T13:34:10.122365","exception":false,"start_time":"2023-12-30T13:34:10.102557","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow as tf\n","import os\n","\n","# Define sample preprocessing pipeline\n","def process_path(file_path, class_names, cut=224, S=256, max_delta=0.2):\n","    \n","    # Convert the compressed string to a 3D uint8 tensor\n","    image = tf.io.read_file(file_path)\n","    image = tf.io.decode_jpeg(image, channels=3)\n","   \n","    # Find rescaling factor\n","    min_side = tf.math.minimum(tf.shape(image)[0], tf.shape(image)[1])\n","    scale = S / min_side\n","    \n","    # Zero-mean the RGB values by ImageNet Mean\n","    image = tf.keras.applications.vgg16.preprocess_input(image)\n","\n","    # Compute new dimensions\n","    new_height = tf.cast(tf.shape(image)[0], tf.float64) * scale\n","    new_width = tf.cast(tf.shape(image)[1], tf.float64) * scale\n","    \n","    # Convert to float\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    # Rescale by S\n","    image = tf.image.resize(image, size=(new_height, new_width), preserve_aspect_ratio=True)\n","    # Crop randomly\n","    image = tf.image.random_crop(image, size=[cut, cut, 3])\n","    # adjust RGB values by random amount\n","    image = tf.image.random_hue(image, max_delta=max_delta)\n","    \n","    # Split file path into parts\n","    parts = tf.strings.split(file_path, os.path.sep)\n","    # Extract class dir name\n","    one_hot = parts[-2] == class_names\n","    # Find index of maximum\n","    label = tf.argmax(one_hot)\n","    \n","    return image, label"]},{"cell_type":"code","execution_count":3,"id":"30394434","metadata":{"execution":{"iopub.execute_input":"2023-12-30T13:34:10.131Z","iopub.status.busy":"2023-12-30T13:34:10.130588Z","iopub.status.idle":"2023-12-30T13:34:10.136362Z","shell.execute_reply":"2023-12-30T13:34:10.135293Z"},"papermill":{"duration":0.013072,"end_time":"2023-12-30T13:34:10.138912","exception":false,"start_time":"2023-12-30T13:34:10.12584","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","# Generate SGD optimiser\n","def create_optimiser():\n","    \n","    sgd_optimiser = keras.optimizers.experimental.SGD(\n","            learning_rate=1e-2,\n","            momentum=0.9,\n","            nesterov=False,\n","            weight_decay=5e-4\n","        )\n","    \n","    return sgd_optimiser"]},{"cell_type":"code","execution_count":4,"id":"7fa87896","metadata":{"execution":{"iopub.execute_input":"2023-12-30T13:34:10.14829Z","iopub.status.busy":"2023-12-30T13:34:10.147844Z","iopub.status.idle":"2023-12-30T13:34:10.160979Z","shell.execute_reply":"2023-12-30T13:34:10.159536Z"},"papermill":{"duration":0.021024,"end_time":"2023-12-30T13:34:10.163647","exception":false,"start_time":"2023-12-30T13:34:10.142623","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","\n","# Build VGG11 model\n","def design_vgg11(class_num, input_shape, kernel_size, padding, activation, pool_size, strides):\n","    \n","    model = keras.models.Sequential([\n","\n","        # 1st convolutional block\n","        layers.Conv2D(input_shape=input_shape, filters=64, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n","\n","        # 2nd convolutional block\n","        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n","\n","        # 3rd convolutional block\n","        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # 4th convolutional block\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # 5th convolutional block\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # Classifier head\n","        layers.Flatten(),\n","        layers.Dense(4096, activation=activation),\n","        layers.Dropout(rate=0.5),\n","        layers.Dense(4096, activation=activation),\n","        layers.Dropout(rate=0.5),\n","        layers.Dense(class_num)\n","    ])\n","    \n","    return model"]},{"cell_type":"code","execution_count":5,"id":"a03059c7","metadata":{"execution":{"iopub.execute_input":"2023-12-30T13:34:10.172929Z","iopub.status.busy":"2023-12-30T13:34:10.17253Z","iopub.status.idle":"2023-12-30T13:34:10.185939Z","shell.execute_reply":"2023-12-30T13:34:10.184574Z"},"papermill":{"duration":0.021417,"end_time":"2023-12-30T13:34:10.18875","exception":false,"start_time":"2023-12-30T13:34:10.167333","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","\n","# Build VGG13 model\n","def design_vgg13(model_file, kernel_size, padding, activation, pool_size, strides, layer_positions=[0, 2, 4, 5, 14, 16, 18]):\n","    \n","    # Import pretrained base\n","    pretrained_base = keras.models.load_model(model_file)\n","    \n","    # Select relevant layers\n","    pretrained_layers = [pretrained_base.get_layer(index=i) for i in layer_positions]\n","    \n","    model = keras.models.Sequential([\n","\n","        # 1st convolutional block\n","        pretrained_layers[0],\n","        layers.Conv2D(filters=64, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n","\n","        # 2nd convolutional block\n","        pretrained_layers[1],\n","        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n","\n","        # 3rd convolutional block\n","        pretrained_layers[2],\n","        pretrained_layers[3],\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # 4th convolutional block\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # 5th convolutional block\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # Classifier head\n","        layers.Flatten(),\n","        pretrained_layers[4],\n","        layers.Dropout(rate=0.5),\n","        pretrained_layers[5],\n","        layers.Dropout(rate=0.5),\n","        pretrained_layers[6],\n","    ])\n","    \n","    return model"]},{"cell_type":"code","execution_count":6,"id":"55404b69","metadata":{"execution":{"iopub.execute_input":"2023-12-30T13:34:10.198684Z","iopub.status.busy":"2023-12-30T13:34:10.198276Z","iopub.status.idle":"2023-12-30T13:34:10.21282Z","shell.execute_reply":"2023-12-30T13:34:10.211503Z"},"papermill":{"duration":0.022626,"end_time":"2023-12-30T13:34:10.215309","exception":false,"start_time":"2023-12-30T13:34:10.192683","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","\n","# Build VGG13 model\n","def design_vgg16(model_file, kernel_size, padding, activation, pool_size, strides, layer_positions=[0, 2, 4, 5, 14, 16, 18]):\n","    \n","    # Import pretrained base\n","    pretrained_base = keras.models.load_model(model_file)\n","    \n","    # Select relevant layers\n","    pretrained_layers = [pretrained_base.get_layer(index=i) for i in layer_positions]\n","    \n","    model = keras.models.Sequential([\n","\n","        # 1st convolutional block\n","        pretrained_layers[0],\n","        layers.Conv2D(filters=64, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n","\n","        # 2nd convolutional block\n","        pretrained_layers[1],\n","        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n","\n","        # 3rd convolutional block\n","        pretrained_layers[2],\n","        pretrained_layers[3],\n","        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # 4th convolutional block\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # 5th convolutional block\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # Classifier head\n","        layers.Flatten(),\n","        pretrained_layers[4],\n","        layers.Dropout(rate=0.5),\n","        pretrained_layers[5],\n","        layers.Dropout(rate=0.5),\n","        pretrained_layers[6],\n","    ])\n","    \n","    return model"]},{"cell_type":"code","execution_count":7,"id":"72431b8d","metadata":{"execution":{"iopub.execute_input":"2023-12-30T13:34:10.224563Z","iopub.status.busy":"2023-12-30T13:34:10.224121Z","iopub.status.idle":"2023-12-30T13:34:10.241267Z","shell.execute_reply":"2023-12-30T13:34:10.24008Z"},"papermill":{"duration":0.024872,"end_time":"2023-12-30T13:34:10.243911","exception":false,"start_time":"2023-12-30T13:34:10.219039","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","\n","# Build VGG13 model\n","def design_vgg19(model_file, kernel_size, padding, activation, pool_size, strides, layer_positions=[0, 2, 4, 5, 14, 16, 18]):\n","    \n","    # Import pretrained base\n","    pretrained_base = keras.models.load_model(model_file)\n","    \n","    # Select relevant layers\n","    pretrained_layers = [pretrained_base.get_layer(index=i) for i in layer_positions]\n","    \n","    model = keras.models.Sequential([\n","\n","        # 1st convolutional block\n","        pretrained_layers[0],\n","        layers.Conv2D(filters=64, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n","\n","        # 2nd convolutional block\n","        pretrained_layers[1],\n","        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n","\n","        # 3rd convolutional block\n","        pretrained_layers[2],\n","        pretrained_layers[3],\n","        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # 4th convolutional block\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # 5th convolutional block\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n","        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n","\n","        # Classifier head\n","        layers.Flatten(),\n","        pretrained_layers[4],\n","        layers.Dropout(rate=0.5),\n","        pretrained_layers[5],\n","        layers.Dropout(rate=0.5),\n","        pretrained_layers[6],\n","    ])\n","    \n","    return model"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":20.507911,"end_time":"2023-12-30T13:34:11.673481","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-30T13:33:51.16557","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}