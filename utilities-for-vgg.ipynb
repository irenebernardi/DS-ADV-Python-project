{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10faeeba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:45:15.875234Z",
     "iopub.status.busy": "2023-12-27T10:45:15.874536Z",
     "iopub.status.idle": "2023-12-27T10:45:30.040556Z",
     "shell.execute_reply": "2023-12-27T10:45:30.039587Z"
    },
    "papermill": {
     "duration": 14.173723,
     "end_time": "2023-12-27T10:45:30.043494",
     "exception": false,
     "start_time": "2023-12-27T10:45:15.869771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.random import set_seed\n",
    "from os import environ\n",
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "# Prepare a reproducible environment for model training and validation\n",
    "def reproduce_environment(random_state=123):\n",
    "\n",
    "    # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    environ[\"PYTHONHASHSEED\"] = str(random_state)\n",
    "\n",
    "    # 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "    seed(random_state)\n",
    "\n",
    "    # 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "    set_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b75e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:45:30.053212Z",
     "iopub.status.busy": "2023-12-27T10:45:30.052305Z",
     "iopub.status.idle": "2023-12-27T10:45:30.059145Z",
     "shell.execute_reply": "2023-12-27T10:45:30.058354Z"
    },
    "papermill": {
     "duration": 0.014215,
     "end_time": "2023-12-27T10:45:30.061629",
     "exception": false,
     "start_time": "2023-12-27T10:45:30.047414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Define label extractor for train samples\n",
    "def extract_train_label(file_path, class_names, devel_files, y_devel):\n",
    "    \n",
    "    # Split file path into parts\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # Extract class dir name\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Find index of maximum\n",
    "    label = tf.argmax(one_hot)\n",
    "    \n",
    "    return label\n",
    "\n",
    "# Define label extractor for devel samples\n",
    "def extract_devel_label(file_path, class_names, devel_files, y_devel):\n",
    "    \n",
    "    # One-hot encode indices\n",
    "    idx_hot = devel_files == file_path\n",
    "    # Find index\n",
    "    idx = tf.argmax(idx_hot)\n",
    "    # Extract class name\n",
    "    class_name = tf.gather(y_devel, idx)\n",
    "\n",
    "    # Extract class dir name\n",
    "    one_hot = class_name == class_names\n",
    "    # Find index of maximum\n",
    "    label = tf.argmax(one_hot)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5884e8ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:45:30.070683Z",
     "iopub.status.busy": "2023-12-27T10:45:30.070104Z",
     "iopub.status.idle": "2023-12-27T10:45:30.078317Z",
     "shell.execute_reply": "2023-12-27T10:45:30.077248Z"
    },
    "papermill": {
     "duration": 0.015534,
     "end_time": "2023-12-27T10:45:30.080712",
     "exception": false,
     "start_time": "2023-12-27T10:45:30.065178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define sample preprocessing pipeline\n",
    "def process_path(file_path, class_names, devel_files, y_devel, label_fun=extract_train_label, cut=224, S=256, max_delta=0.2):\n",
    "    \n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "   \n",
    "    # Find rescaling factor\n",
    "    min_side = tf.math.minimum(tf.shape(image)[0], tf.shape(image)[1])\n",
    "    scale = S / min_side\n",
    "    \n",
    "    # Zero-mean the RGB values by ImageNet Mean\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "\n",
    "    # Compute new dimensions\n",
    "    new_height = tf.cast(tf.shape(image)[0], tf.float64) * scale\n",
    "    new_width = tf.cast(tf.shape(image)[1], tf.float64) * scale\n",
    "    \n",
    "    # Convert to float\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Rescale by S\n",
    "    image = tf.image.resize(image, size=(new_height, new_width), preserve_aspect_ratio=True)\n",
    "    # Crop randomly\n",
    "    image = tf.image.random_crop(image, size=[cut, cut, 3])\n",
    "    # adjust RGB values by random amount\n",
    "    image = tf.image.random_hue(image, max_delta=max_delta)\n",
    "    \n",
    "    label = label_fun(file_path, class_names, devel_files, y_devel)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e3ba89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:45:30.087677Z",
     "iopub.status.busy": "2023-12-27T10:45:30.087291Z",
     "iopub.status.idle": "2023-12-27T10:45:30.092804Z",
     "shell.execute_reply": "2023-12-27T10:45:30.091784Z"
    },
    "papermill": {
     "duration": 0.011845,
     "end_time": "2023-12-27T10:45:30.095416",
     "exception": false,
     "start_time": "2023-12-27T10:45:30.083571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Generate SGD optimiser\n",
    "def create_optimiser():\n",
    "    \n",
    "    sgd_optimiser = keras.optimizers.experimental.SGD(\n",
    "            learning_rate=1e-2,\n",
    "            momentum=0.9,\n",
    "            nesterov=False,\n",
    "            weight_decay=5e-4\n",
    "        )\n",
    "    \n",
    "    return sgd_optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14ea03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:45:30.104345Z",
     "iopub.status.busy": "2023-12-27T10:45:30.103912Z",
     "iopub.status.idle": "2023-12-27T10:45:30.114469Z",
     "shell.execute_reply": "2023-12-27T10:45:30.113217Z"
    },
    "papermill": {
     "duration": 0.018233,
     "end_time": "2023-12-27T10:45:30.117223",
     "exception": false,
     "start_time": "2023-12-27T10:45:30.098990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Build VGG11 model\n",
    "def design_vgg11(class_num, input_shape, kernel_size, padding, activation, pool_size, strides):\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        # 1st convolutional block\n",
    "        layers.Conv2D(input_shape=input_shape, filters=64, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 2nd convolutional block\n",
    "        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 3rd convolutional block\n",
    "        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 4th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 5th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # Classifier head\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation=activation),\n",
    "        layers.Dropout(rate=0.5),\n",
    "        layers.Dense(4096, activation=activation),\n",
    "        layers.Dropout(rate=0.5),\n",
    "        layers.Dense(class_num)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428dda08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:45:30.127215Z",
     "iopub.status.busy": "2023-12-27T10:45:30.126764Z",
     "iopub.status.idle": "2023-12-27T10:45:30.136983Z",
     "shell.execute_reply": "2023-12-27T10:45:30.135731Z"
    },
    "papermill": {
     "duration": 0.018602,
     "end_time": "2023-12-27T10:45:30.139803",
     "exception": false,
     "start_time": "2023-12-27T10:45:30.121201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Build VGG13 model\n",
    "def design_vgg13(model_file, kernel_size, padding, activation, pool_size, strides, layer_positions=[0, 2, 4, 5, 14, 16, 18]):\n",
    "    \n",
    "    # Import pretrained base\n",
    "    pretrained_base = keras.models.load_model(model_file)\n",
    "    \n",
    "    # Select relevant layers\n",
    "    pretrained_layers = [pretrained_base.get_layer(index=i) for i in layer_positions]\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        # 1st convolutional block\n",
    "        pretrained_layers[0],\n",
    "        layers.Conv2D(filters=64),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 2nd convolutional block\n",
    "        pretrained_layers[1],\n",
    "        layers.Conv2D(filters=128),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 3rd convolutional block\n",
    "        pretrained_layers[2],\n",
    "        pretrained_layers[3],\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 4th convolutional block\n",
    "        layers.Conv2D(filters=512),\n",
    "        layers.Conv2D(filters=512),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 5th convolutional block\n",
    "        layers.Conv2D(filters=512),\n",
    "        layers.Conv2D(filters=512),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # Classifier head\n",
    "        layers.Flatten(),\n",
    "        pretrained_layers[4],\n",
    "        layers.Dropout(rate=0.5),\n",
    "        pretrained_layers[5],\n",
    "        layers.Dropout(rate=0.5),\n",
    "        pretrained_layers[6],\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.756751,
   "end_time": "2023-12-27T10:45:31.467496",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-27T10:45:12.710745",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
