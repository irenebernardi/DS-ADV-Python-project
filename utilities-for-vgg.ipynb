{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c941dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:45:21.723381Z",
     "iopub.status.busy": "2023-12-27T09:45:21.722519Z",
     "iopub.status.idle": "2023-12-27T09:45:37.866533Z",
     "shell.execute_reply": "2023-12-27T09:45:37.865467Z"
    },
    "papermill": {
     "duration": 16.152291,
     "end_time": "2023-12-27T09:45:37.869278",
     "exception": false,
     "start_time": "2023-12-27T09:45:21.716987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Define label extractor for train samples\n",
    "def extract_train_label(file_path, class_names, devel_files, y_devel):\n",
    "    \n",
    "    # Split file path into parts\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # Extract class dir name\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Find index of maximum\n",
    "    label = tf.argmax(one_hot)\n",
    "    \n",
    "    return label\n",
    "\n",
    "# Define label extractor for devel samples\n",
    "def extract_devel_label(file_path, class_names, devel_files, y_devel):\n",
    "    \n",
    "    # One-hot encode indices\n",
    "    idx_hot = devel_files == file_path\n",
    "    # Find index\n",
    "    idx = tf.argmax(idx_hot)\n",
    "    # Extract class name\n",
    "    class_name = tf.gather(y_devel, idx)\n",
    "\n",
    "    # Extract class dir name\n",
    "    one_hot = class_name == class_names\n",
    "    # Find index of maximum\n",
    "    label = tf.argmax(one_hot)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d8525e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:45:37.878508Z",
     "iopub.status.busy": "2023-12-27T09:45:37.877435Z",
     "iopub.status.idle": "2023-12-27T09:45:37.888528Z",
     "shell.execute_reply": "2023-12-27T09:45:37.887517Z"
    },
    "papermill": {
     "duration": 0.018738,
     "end_time": "2023-12-27T09:45:37.891334",
     "exception": false,
     "start_time": "2023-12-27T09:45:37.872596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define sample preprocessing pipeline\n",
    "def process_path(file_path, class_names, devel_files, y_devel, label_fun=extract_train_label, cut=224, S=256, max_delta=0.2):\n",
    "    \n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "   \n",
    "    # Find rescaling factor\n",
    "    min_side = tf.math.minimum(tf.shape(image)[0], tf.shape(image)[1])\n",
    "    scale = S / min_side\n",
    "    \n",
    "    # Zero-mean the RGB values by ImageNet Mean\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "\n",
    "    # Compute new dimensions\n",
    "    new_height = tf.cast(tf.shape(image)[0], tf.float64) * scale\n",
    "    new_width = tf.cast(tf.shape(image)[1], tf.float64) * scale\n",
    "    \n",
    "    # Convert to float\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Rescale by S\n",
    "    image = tf.image.resize(image, size=(new_height, new_width), preserve_aspect_ratio=True)\n",
    "    # Crop randomly\n",
    "    image = tf.image.random_crop(image, size=[cut, cut, 3])\n",
    "    # adjust RGB values by random amount\n",
    "    image = tf.image.random_hue(image, max_delta=max_delta)\n",
    "    \n",
    "    label = label_fun(file_path, class_names, devel_files, y_devel)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1452cc64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:45:37.900068Z",
     "iopub.status.busy": "2023-12-27T09:45:37.898902Z",
     "iopub.status.idle": "2023-12-27T09:45:37.906143Z",
     "shell.execute_reply": "2023-12-27T09:45:37.904752Z"
    },
    "papermill": {
     "duration": 0.014943,
     "end_time": "2023-12-27T09:45:37.909364",
     "exception": false,
     "start_time": "2023-12-27T09:45:37.894421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Generate SGD optimiser\n",
    "def create_optimiser():\n",
    "    \n",
    "    sgd_optimiser = keras.optimizers.experimental.SGD(\n",
    "            learning_rate=1e-2,\n",
    "            momentum=0.9,\n",
    "            nesterov=False,\n",
    "            weight_decay=5e-4\n",
    "        )\n",
    "    \n",
    "    return sgd_optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23cc5f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:45:37.917588Z",
     "iopub.status.busy": "2023-12-27T09:45:37.916870Z",
     "iopub.status.idle": "2023-12-27T09:45:37.931972Z",
     "shell.execute_reply": "2023-12-27T09:45:37.930884Z"
    },
    "papermill": {
     "duration": 0.022078,
     "end_time": "2023-12-27T09:45:37.934530",
     "exception": false,
     "start_time": "2023-12-27T09:45:37.912452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Build VGG11 model\n",
    "def design_vgg11(class_num, input_shape, kernel_size, padding, activation, pool_size, strides):\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        # 1st convolutional block\n",
    "        layers.Conv2D(input_shape=input_shape, filters=64, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 2nd convolutional block\n",
    "        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 3rd convolutional block\n",
    "        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=256, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 4th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 5th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # Classifier head\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation=activation),\n",
    "        layers.Dropout(rate=0.5),\n",
    "        layers.Dense(4096, activation=activation),\n",
    "        layers.Dropout(rate=0.5),\n",
    "        layers.Dense(class_num)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46613b9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T09:45:37.943607Z",
     "iopub.status.busy": "2023-12-27T09:45:37.942553Z",
     "iopub.status.idle": "2023-12-27T09:45:37.956647Z",
     "shell.execute_reply": "2023-12-27T09:45:37.955314Z"
    },
    "papermill": {
     "duration": 0.021976,
     "end_time": "2023-12-27T09:45:37.959783",
     "exception": false,
     "start_time": "2023-12-27T09:45:37.937807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Build VGG13 model\n",
    "def design_vgg13(model_file, kernel_size, padding, activation, pool_size, strides, layer_positions=[0, 2, 4, 5, 14, 16, 18]):\n",
    "    \n",
    "    # Import pretrained base\n",
    "    pretrained_base = keras.models.load_model(model_file)\n",
    "    \n",
    "    # Select relevant layers\n",
    "    pretrained_layers = [pretrained_base.get_layer(index=i) for i in layer_positions]\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "\n",
    "        # 1st convolutional block\n",
    "        pretrained_layers[0],\n",
    "        layers.Conv2D(filters=64, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 2nd convolutional block\n",
    "        pretrained_layers[1],\n",
    "        layers.Conv2D(filters=128, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPooling2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 3rd convolutional block\n",
    "        pretrained_layers[2],\n",
    "        pretrained_layers[3],\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 4th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # 5th convolutional block\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.Conv2D(filters=512, kernel_size=kernel_size, padding=padding, activation=activation),\n",
    "        layers.MaxPool2D(pool_size=pool_size, strides=strides),\n",
    "\n",
    "        # Classifier head\n",
    "        layers.Flatten(),\n",
    "        pretrained_layers[4],\n",
    "        layers.Dropout(rate=0.5),\n",
    "        pretrained_layers[5],\n",
    "        layers.Dropout(rate=0.5),\n",
    "        pretrained_layers[6],\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.449584,
   "end_time": "2023-12-27T09:45:39.490240",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-27T09:45:18.040656",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
