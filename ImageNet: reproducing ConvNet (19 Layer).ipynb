{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6799,"databundleVersionId":4225553,"sourceType":"competition"},{"sourceId":7293121,"sourceType":"datasetVersion","datasetId":4229974},{"sourceId":156719079,"sourceType":"kernelVersion"}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":182.446391,"end_time":"2023-12-15T20:38:42.871780","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-15T20:35:40.425389","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nThis is a follw-up notebook to [ImageNet: reproducing ConvNet](https://www.kaggle.com/code/giuliobenedetti/imagenet-reproducing-convnets/)\n\nFor details on the project, click the link.","metadata":{}},{"cell_type":"code","source":"# Import packages\n\n# Data analysis\nimport numpy as np\nimport pandas as pd\n\n# File management\nimport os\nimport shutil\n\n# Image visualisation\nimport matplotlib.pyplot as plt\n\n# Neural network\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\n\n# Custom utilities\nimport utilities_for_vgg as vggutils\n\n# Hide warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"papermill":{"duration":13.410372,"end_time":"2023-12-15T20:35:56.924516","exception":false,"start_time":"2023-12-15T20:35:43.514144","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-27T19:00:50.652600Z","iopub.execute_input":"2023-12-27T19:00:50.652946Z","iopub.status.idle":"2023-12-27T19:00:53.839076Z","shell.execute_reply.started":"2023-12-27T19:00:50.652916Z","shell.execute_reply":"2023-12-27T19:00:53.837512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TPU implementation\nBecause of the long runtimes, use of the Kaggle TPU accelerator is adviced when training a model.","metadata":{}},{"cell_type":"code","source":"# If TPU is available\ntry:\n    # Detect TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\n\nexcept:\n    tpu = None\n    \n\n# If TPU is defined\nif tpu:\n    # Initialise TPU\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    # Instantiate a TPU distribution strategy\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nelse:\n    # Or instanstiate available strategy\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:00:56.909895Z","iopub.execute_input":"2023-12-27T19:00:56.910734Z","iopub.status.idle":"2023-12-27T19:00:56.917604Z","shell.execute_reply.started":"2023-12-27T19:00:56.910699Z","shell.execute_reply":"2023-12-27T19:00:56.916719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define constants\n\n# Set seed for reproducibility\nSEED = 0\n# Set batch size for mini-batch gradient descent\nBATCH_SIZE = 256\n# Set number of epochs to train model\nEPOCH_NUM = 60\n","metadata":{"papermill":{"duration":0.011822,"end_time":"2023-12-15T20:35:56.940671","exception":false,"start_time":"2023-12-15T20:35:56.928849","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-27T19:00:58.515580Z","iopub.execute_input":"2023-12-27T19:00:58.515935Z","iopub.status.idle":"2023-12-27T19:00:58.519808Z","shell.execute_reply.started":"2023-12-27T19:00:58.515906Z","shell.execute_reply":"2023-12-27T19:00:58.519212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Memory and Time Constraints\n\nDue to the large amount of data included in the ImageNet dataset, we have trained our version of the model to 127 classes and around 170k images. adding more classes significantly increases memory utilization, and once a threshold is passed it is too much for the current implementation to handle. [Other methods](https://www.kaggle.com/code/austindrake/adbranch-imagenet-reproducing-convnets)  have been created for handling the full dataset (ver. 3), however this method is currently incompatible with accelerators and has an estimated runtime of 12-20 hours per epoch.","metadata":{}},{"cell_type":"code","source":"# Store paths to base, train set and subset dirs\nbase_dir = \"/kaggle/input/imagenet-object-localization-challenge/\"\ndata_dir = base_dir + \"ILSVRC/Data/CLS-LOC/\"\n\n# Fetch train set\nraw_train_ds = tf.data.Dataset.list_files(data_dir + \"train/n01*/*.JPEG\", shuffle=False)\n\n# Find size of train set\ntrain_size = tf.data.experimental.cardinality(raw_train_ds).numpy()\n\n# Shuffle train set\nraw_train_ds = raw_train_ds.shuffle(train_size, reshuffle_each_iteration=False, seed=SEED)\n\nprint(f\"Size of train set: {train_size}\")","metadata":{"papermill":{"duration":37.284794,"end_time":"2023-12-15T20:36:34.229238","exception":false,"start_time":"2023-12-15T20:35:56.944444","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-27T19:01:00.220583Z","iopub.execute_input":"2023-12-27T19:01:00.221217Z","iopub.status.idle":"2023-12-27T19:01:24.570455Z","shell.execute_reply.started":"2023-12-27T19:01:00.221174Z","shell.execute_reply":"2023-12-27T19:01:24.569207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import and extract devel labels\ndevel_df = pd.read_csv(base_dir + \"LOC_val_solution.csv\")\ny_devel = devel_df[\"PredictionString\"].str.split(expand=True)[0]\n\n# Select devel images belonging to subset of classes\nkeep = np.where(y_devel.str.startswith(\"n01\").to_numpy())[0]\ndevel_files = np.array(os.listdir(data_dir + \"val/\"))[keep]\n\n# Fetch devel set\ndevel_files = np.array([data_dir + \"val/\" + file for file in devel_files])\nraw_devel_ds = tf.data.Dataset.list_files(devel_files, shuffle=False)\n\n# Select labels belonging to subset of classes\ny_devel = y_devel[y_devel.str.startswith(\"n01\")].values\n\n# Find size of devel set\ndevel_size = tf.data.experimental.cardinality(raw_devel_ds).numpy()\n\nprint(f\"Size of devel set: {devel_size}\")\nprint(\"Examples of labels:\")\ny_devel[:10]","metadata":{"papermill":{"duration":0.365818,"end_time":"2023-12-15T20:36:34.599210","exception":false,"start_time":"2023-12-15T20:36:34.233392","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-27T19:01:27.205539Z","iopub.execute_input":"2023-12-27T19:01:27.205876Z","iopub.status.idle":"2023-12-27T19:01:53.100830Z","shell.execute_reply.started":"2023-12-27T19:01:27.205850Z","shell.execute_reply":"2023-12-27T19:01:53.100212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"# Find class names from dir names\nclass_names = np.array(sorted([dir for dir in os.listdir(data_dir + \"train/\") if dir.startswith(\"n01\")]))\n\n# Set number of classes\nCLASS_NUM = len(class_names)\n\nfor f in raw_train_ds.take(5):\n    print(f.numpy())","metadata":{"papermill":{"duration":0.62452,"end_time":"2023-12-15T20:36:35.236815","exception":false,"start_time":"2023-12-15T20:36:34.612295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-27T19:14:09.899144Z","iopub.execute_input":"2023-12-27T19:14:09.899857Z","iopub.status.idle":"2023-12-27T19:14:10.110279Z","shell.execute_reply.started":"2023-12-27T19:14:09.899823Z","shell.execute_reply":"2023-12-27T19:14:10.108628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = vggutils.process_path(\n    data_dir + \"val/ILSVRC2012_val_00046886.JPEG\",\n    class_names,\n    devel_files,\n    y_devel,\n    label_fun=vggutils.extract_devel_label\n)\n\ninput_shape = image.shape\n\nplt.imshow(image)\nprint(label)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:14:14.539437Z","iopub.execute_input":"2023-12-27T19:14:14.539804Z","iopub.status.idle":"2023-12-27T19:14:15.159049Z","shell.execute_reply.started":"2023-12-27T19:14:14.539774Z","shell.execute_reply":"2023-12-27T19:14:15.157717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess train set\ntrain_ds = raw_train_ds.map(\n    lambda path: vggutils.process_path(path, class_names, devel_files, y_devel, label_fun=vggutils.extract_train_label),\n    num_parallel_calls=tf.data.AUTOTUNE\n)\n\n# Preprocess devel set\ndevel_ds = raw_devel_ds.map(\n    lambda path: vggutils.process_path(path, class_names, devel_files, y_devel, label_fun=vggutils.extract_train_label, max_delta=0),\n    num_parallel_calls=tf.data.AUTOTUNE\n)\n\n# Show example\nfor image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:14:21.158659Z","iopub.execute_input":"2023-12-27T19:14:21.159026Z","iopub.status.idle":"2023-12-27T19:14:22.009536Z","shell.execute_reply.started":"2023-12-27T19:14:21.158997Z","shell.execute_reply":"2023-12-27T19:14:22.008066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Improve train set performance\ntrain_ds = train_ds \\\n    .cache() \\\n    .shuffle(buffer_size=1000, seed=SEED) \\\n    .batch(BATCH_SIZE) \\\n    .prefetch(buffer_size=tf.data.AUTOTUNE)\n\n# Improve devel set performance\ndevel_ds = devel_ds \\\n    .batch(BATCH_SIZE) \\\n    .cache() \\\n    .prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:14:31.419871Z","iopub.execute_input":"2023-12-27T19:14:31.420317Z","iopub.status.idle":"2023-12-27T19:14:31.440586Z","shell.execute_reply.started":"2023-12-27T19:14:31.420283Z","shell.execute_reply":"2023-12-27T19:14:31.439596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_batch, label_batch = next(iter(train_ds))\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image_batch[i])\n    label = label_batch[i]\n    plt.title(class_names[label])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:14:34.206395Z","iopub.execute_input":"2023-12-27T19:14:34.206749Z","iopub.status.idle":"2023-12-27T19:14:44.769891Z","shell.execute_reply.started":"2023-12-27T19:14:34.206723Z","shell.execute_reply":"2023-12-27T19:14:44.769227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning from VGG11\n\nAs per the [original paper](https://arxiv.org/pdf/1409.1556v6.pdf), the weights from the first four convolutional layers and three fully connected layers will be transferred to deeper models to initialize the weights. These layers will still be trainable. All other layers will have weights initialized to a normal distribution around mean 0 with variance 10e-2 (std = 0.1)","metadata":{}},{"cell_type":"code","source":"#Transfer Learning\n# Import pretrained base\nmodel_file = \"/kaggle/input/vgg-11-model\"\n\n# Save model into file for replication purposes\n\nnew_model = tf.keras.models.load_model(model_file)\n\n# IMPORTANT: Set weights from base as untrainable\nnew_model.trainable = True","metadata":{"execution":{"iopub.status.busy":"2023-12-27T19:15:01.565464Z","iopub.execute_input":"2023-12-27T19:15:01.565886Z","iopub.status.idle":"2023-12-27T19:15:02.161766Z","shell.execute_reply.started":"2023-12-27T19:15:01.565852Z","shell.execute_reply":"2023-12-27T19:15:02.159683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List indices of relevant layers (only convolutional, no maxpool)\nlayer_positions = [0, 2, 4, 5, 14, 16, 18]\n\n# Select relevant layers\npretrained_layers = [new_model.get_layer(index=i) for i in layer_positions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build 19 layer model\ndef design_vgg19():\n\n    model = tf.keras.models.Sequential()\n\n    model.add(pretrained_layers[0]) #conv3-64 layer 1\n    model.add(layers.Conv2D(64, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1) , activation='relu',padding= \"same\", name='19_layer_2' )) #conv3-64 layer 2\n    model.add(layers.MaxPooling2D((2, 2), strides = (2,2))) #maxpool 1\n\n    model.add(pretrained_layers[1]) #conv3-128 layer 3\n    model.add(layers.Conv2D(128, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_4' )) #conv3-128 layer 4\n    model.add(layers.MaxPooling2D((2, 2), strides = (2,2))) #maxpool 2\n\n    model.add(pretrained_layers[2]) #conv3-256 layer 5\n    model.add(pretrained_layers[3]) #conv3-256 layer 6\n    model.add(layers.Conv2D(256, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_7' )) #conv3-256 layer 7\n    model.add(layers.Conv2D(256, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_8' )) #conv3-256 layer 8\n    model.add(layers.MaxPooling2D((2, 2), strides = (2,2))) #maxpool 3\n\n    model.add(layers.Conv2D(512, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_9')) #conv3-512 layer 9\n    model.add(layers.Conv2D(512, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_10')) #conv3-512 layer 10\n    model.add(layers.Conv2D(512, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_11')) #conv3-512 layer 11\n    model.add(layers.Conv2D(512, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_12')) #conv3-512 layer 12\n    model.add(layers.MaxPooling2D((2, 2), strides = (2,2))) #maxpool 4\n\n    model.add(layers.Conv2D(512, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_13')) #conv3-512 layer 13\n    model.add(layers.Conv2D(512, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_14')) #conv3-512 layer 14\n    model.add(layers.Conv2D(512, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_15')) #conv3-512 layer 15\n    model.add(layers.Conv2D(512, (3, 3), kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1), activation='relu',padding= \"same\", name='19_layer_16')) #conv3-512 layer 16\n    model.add(layers.MaxPooling2D((2, 2), strides = (2,2))) #maxpool 5 - final\n\n    model.add(layers.Flatten()) #necessary for 1D Dense layer\n    model.add(pretrained_layers[4]) # FC 1 layer 17\n    model.add(layers.Dropout(0.5))\n    model.add(pretrained_layers[5]) #FC 2 layer 18\n    model.add(layers.Dropout(0.5))\n    model.add(pretrained_layers[6]) # FC 3 layer 19","metadata":{"papermill":{"duration":1.61823,"end_time":"2023-12-15T20:36:36.884458","exception":false,"start_time":"2023-12-15T20:36:35.266228","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up model within scope of tpu strategy\nwith strategy.scope():\n    \n    # Make environment more reproducible\n    vggutils.reproduce_environment(random_state=SEED)\n    \n    # Build model\n    model = design_vgg19()\n    \n    # Define optimiser\n    sgd_optimiser = vggutils.create_optimiser()\n    \n    # Compile model\n    model.compile(\n        optimizer = sgd_optimiser,\n        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[\"sparse_categorical_accuracy\"]\n    )","metadata":{"papermill":{"duration":123.543668,"end_time":"2023-12-15T20:38:40.532673","exception":false,"start_time":"2023-12-15T20:36:36.989005","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Update learning rate\nLR_Decay = keras.callbacks.ReduceLROnPlateau(\n    monitor=\"loss\",\n    factor=0.1,\n    patience=2,\n    mode=\"min\",\n    min_delta=1e-4,\n    min_lr=1e-5\n)\n\n# Train the model\nhistory = model.fit(\n    train_ds,\n    validation_data=devel_ds,\n    epochs=EPOCH_NUM,\n    batch_size=BATCH_SIZE,\n    verbose=True,\n    callbacks=[LR_Decay]\n)\n\n# Store training history as a dataframe\nhistory_df = pd.DataFrame(history.history)\n\nprint(f\"Train loss: {history_df['loss'].iloc[-1]:.3f}, Devel loss: {history_df['val_loss'].iloc[-1]:.3f}\")\nprint(f\"Train accuracy: {history_df['sparse_categorical_accuracy'].iloc[-1]:.3f}, Devel accuracy: {history_df['val_sparse_categorical_accuracy'].iloc[-1]:.3f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize the Results","metadata":{}},{"cell_type":"code","source":"# Visualise loss\nhistory_df.loc[:, [\"loss\", \"val_loss\"]].plot(title=\"Loss\")","metadata":{"papermill":{"duration":0.260918,"end_time":"2023-12-15T20:38:40.805319","exception":false,"start_time":"2023-12-15T20:38:40.544401","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualise accuracy\nhistory_df.loc[:, [\"sparse_categorical_accuracy\", \"val_sparse_categorical_accuracy\"]].plot(title=\"Accuracy\")","metadata":{"papermill":{"duration":0.019093,"end_time":"2023-12-15T20:38:40.835355","exception":false,"start_time":"2023-12-15T20:38:40.816262","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}