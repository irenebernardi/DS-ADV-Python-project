{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow \n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of classes to use (this is a way to subset the data)\n",
    "CLASS_NUM = 3\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing \n",
    "# Store paths to base, train set and subset dirs\n",
    "base_dir = \"/kaggle/input/imagenet-object-localization-challenge\"\n",
    "train_dir = base_dir + \"/ILSVRC/Data/CLS-LOC/train\"\n",
    "subset_dir = \"/kaggle/working/data\"\n",
    "\n",
    "if not os.path.exists(subset_dir):\n",
    "    os.mkdir(subset_dir)\n",
    "    print(subset_dir, \"created!\")\n",
    "else:\n",
    "    print(subset_dir, \"already exists!\")\n",
    "    \n",
    "# Select only first n class dirs\n",
    "class_dirs = os.listdir(train_dir)[:CLASS_NUM]\n",
    "\n",
    "# Copy class dir from train set to working dir\n",
    "for class_dir in class_dirs:\n",
    "    # Define current source and destination paths\n",
    "    source_dir = train_dir + \"/\" + class_dir\n",
    "    destination_dir = subset_dir + \"/\" + class_dir\n",
    "    \n",
    "    # If new class, copy to working dir\n",
    "    if not os.path.exists(destination_dir):\n",
    "        shutil.copytree(source_dir, destination_dir)\n",
    "        print(class_dir, \"succesfully copied!\")\n",
    "    # If it exists, don't copy again\n",
    "    else:\n",
    "        print(class_dir, \"doesn't need copying!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in image\n",
    "image = imread(subset_dir + \"/n02098413/n02098413_720.JPEG\")\n",
    "# Show image\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all image files in the dataset\n",
    "image_files = [f for f in os.listdir(subset_dir) if f.endswith(\".JPEG\")]\n",
    "\n",
    "# Create a list to store resized images\n",
    "resized_images = []\n",
    "\n",
    "# Loop through each image file\n",
    "for image_file in image_files:\n",
    "    # Construct the full path to the image\n",
    "    image_path = os.path.join(subset_dir, image_file)\n",
    "\n",
    "    # Read in the image\n",
    "    image = imread(image_path)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_image = skimage.transform.resize(image, (256, 256, 3))\n",
    "\n",
    "    # Append the resized image to the list\n",
    "    resized_images.append(resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crop by s value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop(image, start_height, start_width, crop_height, crop_width): \n",
    "    #original image shape\n",
    "    original_shape = image.shape\n",
    "    #print(f\"Original image shape: {original_shape}\") just to check rescaling correct\n",
    "    \n",
    "    #Make sure you're cropping to a size that's not higher than the original picture\n",
    "    assert start_height + crop_height <= original_shape[0], \"Invalid crop height\"\n",
    "    assert start_width + crop_width <= original_shape[1], \"Invalid crop width\"\n",
    "    \n",
    "    #crop\n",
    "    cropped_image = image[start_height:start_height + crop_height, start_width:start_width + crop_width, :]\n",
    "    \n",
    "    return cropped_image\n",
    "\n",
    "directory_path = subset_dir\n",
    "\n",
    "#list to store cropped images\n",
    "cropped_images_s256 = []\n",
    "labels = []  #Need to preserve original class labels\n",
    "\n",
    "#Loop through each class directory\n",
    "for class_dir in os.listdir(directory_path):\n",
    "    class_dir_path = os.path.join(directory_path, class_dir)\n",
    "\n",
    "    #Loop through each image file in the class directory\n",
    "    for image_file in os.listdir(class_dir_path):\n",
    "        image_path = os.path.join(class_dir_path, image_file)\n",
    "        \n",
    "       \n",
    "        image = imread(image_path)\n",
    "        \n",
    "\n",
    "        #resized_image = skimage.transform.resize(image, (256, 256, 3))\n",
    "        \n",
    "        if resized_image is not None:\n",
    "            # TODO: Do start values need to be randomized?\n",
    "            start_height = 0  #from the top\n",
    "            start_width = 0   #from the left\n",
    "            crop_height = 224\n",
    "            crop_width = 224\n",
    "\n",
    "            labels.append(class_dir)\n",
    "            \n",
    "            # Crop the image\n",
    "            cropped_image = crop(resized_image, start_height, start_width, crop_height, crop_width)\n",
    "            cropped_images_s256.append(cropped_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check\n",
    "print(cropped_images_s256[0].shape)\n",
    "print(cropped_images_s256[231].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert images to tensors and one-hot encode labels before compiling model\n",
    "images_ds =tf.constant(cropped_images_s256)\n",
    "print(images_ds.shape)\n",
    "labels_one_hot = pd.get_dummies(labels)\n",
    "#get np array\n",
    "labels_one_hot = labels_one_hot.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create convolutional base\n",
    "\n",
    "#refer to table 1 for architecture \n",
    "model = tf.keras.Sequential(name='CNN_11_layer_trial')\n",
    "\n",
    "#useful comments for understanding layout, once we're all aligned delete: \n",
    "\n",
    "#Spatial pooling is carried out by five max-pooling layers, which follow some of the conv. layers (not all the conv. layers are followed\n",
    "#by max-pooling). \n",
    "#Max-pooling is performed over a 2 Ã— 2 pixel window, with stride 2.\n",
    "#for conv layers: increasing filters by *2 for each conv layer, starting at 64 until 512\n",
    "#input shape mandatory in first layer: image shape and 3, stands for RGB\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(224, 224, 3))) #1\n",
    "model.add(layers.MaxPooling2D((2, 2), strides = 2))\n",
    "model.add(layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu')) #2\n",
    "model.add(layers.MaxPooling2D((2, 2), strides = 2)) \n",
    "model.add(layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')) #3\n",
    "model.add(layers.Conv2D(256, (3, 3),  strides=(1, 1), padding='same', activation='relu')) #4\n",
    "model.add(layers.MaxPooling2D((2, 2), strides = 2))\n",
    "model.add(layers.Conv2D(512, (3, 3),  strides=(1, 1), padding='same', activation='relu')) #5\n",
    "model.add(layers.Conv2D(512, (3, 3),  strides=(1, 1), padding='same', activation='relu')) #6\n",
    "model.add(layers.MaxPooling2D((2, 2), strides = 2)) #final maxpool before fully connected layers \n",
    "model.add(layers.Conv2D(512, (3, 3),  strides=(1, 1), padding='same', activation='relu')) #7\n",
    "model.add(layers.Conv2D(512, (3, 3),  strides=(1, 1), padding='same', activation='relu')) #8\n",
    "#5th and last maxpool layer: \n",
    "model.add(layers.MaxPooling2D((2, 2), strides = 2))\n",
    "#9,10,11 are fully conntected layers\n",
    "#9\n",
    "model.add(layers.Flatten()) #dense layers expect flat vectors, not tensors\n",
    "model.add(layers.Dense(4096)) #4096 units\n",
    "layers.Dropout(rate = 0.5)\n",
    "#10\n",
    "model.add(layers.Dense(4096)) #4096 units\n",
    "layers.Dropout(rate = 0.5)\n",
    "#11\n",
    "#layers.Dense (3, activation = 'softmax')\n",
    "model.add(layers.Dense(3)) #1000 units, 1000- way ILSVRC classification; here 3 for subset\n",
    "#softmax before output\n",
    "model.add(tf.keras.layers.Softmax(axis=-1))   #apply softmax to last dimension of input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model \n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Define the optimizer separately so we have better hyperparams control \n",
    "sgd = SGD(lr=0.01, momentum=0.9, weight_decay = 0.0005) #TODO: change learning rate and CHECK WEIGHT DECAU\n",
    "\n",
    "#in 11 layer, paper initializes weights randomly\n",
    "#this is redundant as this is the default initialisation method, keeping just for reference in later models w/ > layers \n",
    "weights = [np.random.rand(*w.shape) for w in model.get_weights()]\n",
    "model.set_weights(weights)\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=sgd,  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss='categorical_crossentropy', #multinomial logistic regression\n",
    "    # List of metrics to monitor\n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    images_ds, \n",
    "    labels_one_hot, #pd.get_dummies(labels)\n",
    "    batch_size= 2, \n",
    "    #validation_split=0.15, #we might not need to do this? as this is just a test \n",
    "    epochs= 2 ) #should be 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The returned history object holds a record of the loss values and metric values during training:\n",
    "'''history_df = pd.DataFrame(history.history)\n",
    "\n",
    "history_df.loc[:, \"loss\"].plot()\n",
    "'''\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: subtract the mean RGB value, computed on the training set, from each pixel\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
